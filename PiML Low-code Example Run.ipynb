{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdsf78IH3_c7"
   },
   "source": [
    "# PiML Toolbox for Model Development and Validation: Low-code Demo\n",
    "\n",
    "PiML (Python Interpretable Machine Learning) is an integrated Python toolbox for IML model development and validation. Through low-code interface and high-code APIs, PiML supports various machine learning models in the following two categories:\n",
    "\n",
    "- **Inherently interpretable models**:\n",
    "\n",
    "    - 1. GLM: Linear/logistic regression with L1 and/or L2 regularization (Hastie, Tibshirani and Wainwright, 2015)\n",
    "\n",
    "    - 2. GAM: Generalized additive models using B-splines (Servén and Brummitt, 2018)\n",
    "\n",
    "    - 3. Tree: Decision tree for classification and regression (Pedregosa et al., 2011)\n",
    "\n",
    "    - 4. FIGS: Fast interpretable greedy-tree sums (Tan et al., 2022)\n",
    "\n",
    "    - 5. XGB1: Extreme gradient boosted trees of depth 1 (Chen and He, 2015)\n",
    "\n",
    "    - 6. XGB2: Extreme gradient boosted trees of depth 2 (Chen and He, 2015; Lengerich et al., 2020)\n",
    "\n",
    "    - 7. EBM: Explainable boosting machine (Nori, et al. 2019; Lou, et al. 2013)\n",
    "\n",
    "    - 8. GAMI-Net: Generalized additive model with structured interactions (Yang, Zhang and Sudjianto, 2021)\n",
    "\n",
    "    - 9. ReLU-DNN: Deep ReLU networks using Aletheia unwrapper and sparsification (Sudjianto, et al. 2020)\n",
    "\n",
    "\n",
    "- **Arbitrary black-box models**，e.g.\n",
    "  1. Tree-ensembles: RF, GBM, XGBoost, LightGBM, ...\n",
    "  2. DNNs: MLP, ResNet, CNN, Attention, ...\n",
    "  3. Kernel methods: SVM, Gaussian Process, ...\n",
    "\n",
    "\n",
    "This example notebook demonstrates how to use PiML in its low-code mode to train machine learning models, then interpret/explain, diagose and compare them. The toolbox has the following built-in datasets for demo purposes. \n",
    "\n",
    "- **CoCircles** classification data: simulated by `sklearn.datasets.make_make_circles(n_samples=2000, noise=0.1)`; see [details](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html).   \n",
    "- **Friedman** regression data: simulated by `sklearn.datasets.make_friedman1(n_samples=2000, n_features=10, and noise=0.1)`; see [details](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman1.html).   \n",
    "- **BikeSharing** regression data from UCI repository: consisting of 17,389 samples of hourly counts of rental bikes in Capital bikeshare system; see [details](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset).  \n",
    "- **CaliforniaHousing** regression data: consisting of 20,640 samples and 9 features, fetched by `sklearn.datasets`; see [details](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html). There are a raw version, a trim1 version (trimming only AveOccup) and a trim2 version (trimming AveRooms, AveBedrms, Population and AveOccup).   \n",
    "- **TaiwanCredit** classification data fro UCI repository: consisting of 30,000 credit card clients in Taiwan from 200504 to 200509; see [details](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients). This data is subject to slight preprocessing. \n",
    "\n",
    "- **SimuCredit**: A credit simulation data for fairness testing.\n",
    "- **SolasSimu1**: A simulated dataset, modified from the 'Friedman #1' regression problem. The covariates used for modeling are 'Segment', 'x1', 'x2', ..., 'x5', the response 'Label' is binary and it is a classification problem. The rest variables are demographic variables used for testing fairness. The data is contributed by Solas-AI (https://github.com/SolasAI/solas-ai-disparity).\n",
    "- **SolasHMDA**: A preprocessed sample of the 2018 Home Mortgage Disclosure Act (HMDA) data. The HMDA dataset includes information about nearly every home mortgage application in the United States.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ7N7REOtAgN"
   },
   "source": [
    "# Stage 0: Install PiML package on Google Colab\n",
    "\n",
    "1. Run `!pip install piml` to install the latest version of PiML\n",
    "2. In Colab, you'll need restart the runtime in order to use newly installed PiML version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jvtEI-M15Xv"
   },
   "outputs": [],
   "source": [
    "!pip install piml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kcbghi53_dB"
   },
   "source": [
    "# Stage 1: Initialize an experiment, Load and Prepare data <a name=\"expdata\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T12:31:46.670393Z",
     "start_time": "2022-04-18T12:31:44.832218Z"
    },
    "id": "EN4UWjkT3_dC"
   },
   "outputs": [],
   "source": [
    "from piml import Experiment\n",
    "exp = Experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T12:31:46.692710Z",
     "start_time": "2022-04-18T12:31:46.674727Z"
    },
    "id": "1HXFMmmB3_dF"
   },
   "outputs": [],
   "source": [
    "exp.data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T12:31:53.491182Z",
     "start_time": "2022-04-18T12:31:53.176711Z"
    },
    "id": "RTcvcydS3_dH",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.data_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T12:31:56.068058Z",
     "start_time": "2022-04-18T12:31:55.591583Z"
    },
    "id": "GmatYRgR3_dJ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.eda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp.data_prepare()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp.feature_select()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp.data_quality()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RN8j7aZU3_dJ"
   },
   "source": [
    "# Stage 2. Train intepretable models <a name=\"modeltrain\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T12:35:42.346210Z",
     "start_time": "2022-04-18T12:35:42.096995Z"
    },
    "id": "WOe59Icm3_dK",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.model_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lu3mpYH33_dK"
   },
   "source": [
    "# Stage 3. Explain and Interpret <a name=\"modelinterpret\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ID9UHiYe5hot"
   },
   "outputs": [],
   "source": [
    "exp.model_explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T12:37:54.174073Z",
     "start_time": "2022-04-18T12:37:54.162680Z"
    },
    "id": "oMgyUf7a3_dK",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.model_interpret()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97AaEXDy5N8L"
   },
   "source": [
    "# Stage 4. Diagnose and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZNCKnDi5Nmo"
   },
   "outputs": [],
   "source": [
    "exp.model_diagnose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzJICjBfxWQl"
   },
   "outputs": [],
   "source": [
    "exp.model_compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp.segmented_diagnose()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTJHgcRwtkpQ"
   },
   "source": [
    "# Stage 5. Register an arbitrary model ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WGJ8PzutkLh"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, XGBMClassifier\n",
    "\n",
    "exp.model_train(model=XGBRegressor(max_depth=7, n_estimators=500), name='XGB7')\n",
    "\n",
    "## To register a pre-trained model, use the following: \n",
    "# pipeline = exp.make_pipeline(model=..., name='...', train_x=..., train_y=..., test_x=..., test_y=...)\n",
    "# exp.register(pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nN712oG40VTr"
   },
   "outputs": [],
   "source": [
    "exp.model_explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7z1D_Z5K0XhA"
   },
   "outputs": [],
   "source": [
    "exp.model_diagnose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USH17YFC4uiR"
   },
   "outputs": [],
   "source": [
    "exp.model_compare()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PiML Low-code Example Run.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
