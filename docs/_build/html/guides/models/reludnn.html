<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>

  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>PiML Toolbox</title>
  

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/jupyter-sphinx.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/thebelab.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3" crossorigin="anonymous"></script>
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/thebelab-helper.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>

</head>

<body class="wy-body-for-nav">

  


<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/piml-logo.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../modules/classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Examples</a>
        </li>
     </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
  <div class="d-flex" id="sk-doc-wrapper">
      <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
      <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
      <div id="sk-sidebar-wrapper" class="border-right">
        <div class="sk-sidebar-toc-wrapper">
          <div class="sk-sidebar-toc-logo">
            <a href="../../index.html">
              <img
                class="sk-brand-img"
                src="../../_static/piml-logo.png"
                alt="logo"/>
            </a>
          </div>
          <!--div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
              <a href="gaminet.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="5.8. GAMI-Net">Prev</a><a href="../models.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="5. Interpretable Models">Up</a>
              <a href="../testing.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6. Diagnostic Suite">Next</a>
          </div-->
              <div class="sk-sidebar-toc">
              
                <ul>
                
                
                
                
                
                
                <li>
                  <a href="../../user_guide.html" class="sk-toc-active">User Guide</a>
                </li>
                <ul>
                
                  <li>
                    <a href="../introduction.html" class="">1. Introduction</a>
                    
                  </li>
                
                  <li>
                    <a href="../data.html" class="">2. Data Pipeline</a>
                    
                  </li>
                
                  <li>
                    <a href="../train.html" class="">3. Model Train and Tune</a>
                    
                  </li>
                
                  <li>
                    <a href="../explain.html" class="">4. Post-hoc Explainability</a>
                    
                  </li>
                
                  <li>
                    <a href="../models.html" class="sk-toc-active">5. Interpretable Models</a>
                    
                    <ul>
                      
                        <li class="sk-toctree-l3">
                          <a href="glm.html">5.1. Generalized Linear Models</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="gam.html">5.2. Generalized Additive Model</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="tree.html">5.3. Decision Tree</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="figs.html">5.4. Fast Interpretable Greedy-tree Sums</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="xgb1.html">5.5. XGBoost Depth 1</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="xgb2.html">5.6. XGBoost Depth 2</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="ebm.html">5.7. Explainable Boosting Machines</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="gaminet.html">5.8. GAMI-Net</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="">5.9. ReLU Neural Network</a>
                        </li>
                      
                    </ul>
                    
                  </li>
                
                  <li>
                    <a href="../testing.html" class="">6. Diagnostic Suite</a>
                    
                  </li>
                
                  <li>
                    <a href="../compare.html" class="">7. Model Comparison</a>
                    
                  </li>
                
                  <li>
                    <a href="../cases.html" class="">8. Case Studies</a>
                    
                  </li>
                
                </ul>
                
                
                
                
                </ul>
              </div>
        </div>
      </div>
      <div id="sk-page-content-wrapper">
        <div class="sk-page-content container-fluid body px-md-3" role="main">
          
  <style type="text/css">
  div.body div.toctree-wrapper ul {
      padding-left: 0;
  }

  div.body li.toctree-l1 {
      padding: 0 0 0.5em 0;
      list-style-type: none;
      font-size: 150%;
      font-weight: bold;
  }

  div.body li.toctree-l2 {
      font-size: 70%;
      list-style-type: square;
      font-weight: normal;
      margin-left: 40px;
  }

  div.body li.toctree-l3 {
      font-size: 85%;
      list-style-type: circle;
      font-weight: normal;
      margin-left: 40px;
  }

  div.body li.toctree-l4 {
      margin-left: 40px;
  }

</style><section id="relu-neural-network">
<h1><span class="section-number">5.9. </span>ReLU Neural Network<a class="headerlink" href="#relu-neural-network" title="Permalink to this heading">¶</a></h1>
<p>Deep neural networks (DNNs) that use the rectified linear unit (ReLU) activation functions have achieved remarkable success. Due to its simple functional form, ReLU offers many appealing properties, such as a fast convergence rate, excellent predictive performance, and intrinsic interpretability. In this section, we will give a brief overview of the ReLU-DNN model and how it is used in PiML.</p>
<section id="model-formulation">
<h2><span class="section-number">5.9.1. </span>Model Formulation<a class="headerlink" href="#model-formulation" title="Permalink to this heading">¶</a></h2>
<p>Consider a feedforward ReLU network with inputs <span class="math notranslate nohighlight">\(\textbf{x} \in \mathbb{R}^{d}\)</span>, <span class="math notranslate nohighlight">\(L\)</span> hidden layers, and one output neuron. Assume the <span class="math notranslate nohighlight">\(l\)</span>-th hidden layer has <span class="math notranslate nohighlight">\(n_{l}\)</span> neurons. In particular, we mark the input layer as a special hidden layer with index 0 (<span class="math notranslate nohighlight">\(n_{0}=d\)</span>). The weight matrix and bias vector of the <span class="math notranslate nohighlight">\(l\)</span>-th hidden layer to the  <span class="math notranslate nohighlight">\((l+1)\)</span>-th hidden layer are denoted by <span class="math notranslate nohighlight">\(\textbf{W}^{(l)}\)</span> of size <span class="math notranslate nohighlight">\(n_{l+1}\times n_{l}\)</span>, and <span class="math notranslate nohighlight">\(\textbf{b}^{l}\)</span> of size <span class="math notranslate nohighlight">\(n_{l+1}\)</span>, respectively. Let <span class="math notranslate nohighlight">\(\textbf{z}^{(l)}\)</span> denotes the input of the <span class="math notranslate nohighlight">\(l\)</span>-th hidden layer. Then, the network can be recursively expressed by</p>
<div class="math notranslate nohighlight">
\[\begin{align}
   \textbf{z}^{(l + 1)}=\textbf{W}^{(l)}\chi^{(l)}+\textbf{b}^{(l)},  \mbox{for } l=0,\ldots,L-1,  \tag{1}
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(\chi^{(l)}\)</span> is the output of the <span class="math notranslate nohighlight">\(l\)</span>-th hidden layer after the ReLU transformation</p>
<div class="math notranslate nohighlight">
\[\begin{align}
   \chi^{(l)} = max\{0,z^{(l)}\}, \mbox{for } l=1,\ldots, L. \tag{2}
\end{align}\]</div>
<p>Finally, the output layer (i.e., the layer <span class="math notranslate nohighlight">\(L + 1\)</span>) is given by</p>
<div class="math notranslate nohighlight">
\[\begin{align}
   \mathbb{E}[y]=\sigma(\eta(\textbf{x}))=\sigma(\textbf{W}^{(L)}\chi^{(L)}+\textbf{b}^{(L)}), \tag{3}
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(\textbf{b}^{(L)}\)</span> is the bias of the output layer, and <span class="math notranslate nohighlight">\(\sigma\)</span> is the activation function, which can be identity (regression) or sigmoid (binary classification).</p>
</section>
<section id="local-linear-models">
<h2><span class="section-number">5.9.2. </span>Local Linear Models<a class="headerlink" href="#local-linear-models" title="Permalink to this heading">¶</a></h2>
<p>Despite the complex model form, the black box of deep ReLU networks can be unwrapped through local linear representations <a class="reference internal" href="../introduction.html#sudjianto2020" id="id1"><span>[Sudjianto2020]</span></a>. First of all, let’s define the activation pattern.</p>
<p><strong>Activation Pattern</strong>: Let the binary vector <span class="math notranslate nohighlight">\(C=[C^{(1)}; \ldots; C^{(L)}]\)</span> indicate the on/off state of each hidden neuron in the network. Specifically, the component <span class="math notranslate nohighlight">\(C^{(l)}\)</span> is called a layered pattern for <span class="math notranslate nohighlight">\(l=1,\ldots,L\)</span>. The activation pattern <span class="math notranslate nohighlight">\(C\)</span> is said to be trivial if there is at least one <span class="math notranslate nohighlight">\(C^{(l)} \equiv 0\)</span> for some <span class="math notranslate nohighlight">\(l\)</span>.</p>
<p>The length of the activation pattern is <span class="math notranslate nohighlight">\(\sum_{i=1}^L n_l\)</span>, i.e., the total number of hidden neurons in the network. Each sample <span class="math notranslate nohighlight">\(\textbf{x}\)</span> corresponds to a particular activation pattern of the form</p>
<div class="math notranslate nohighlight">
\[\begin{equation}
   C(\textbf{x}) = [C^{(1)}(\textbf{x}); \ldots; C^{(L)}(\textbf{x})].
\end{equation}\]</div>
<p>Data points that exhibit the same activation pattern can be grouped, and their input-output relationship can be simplified using a linear model, known as the local linear model (LLM). By disentangling the network, an equivalent set of LLMs can be obtained.</p>
<div class="math notranslate nohighlight">
\[\begin{align}
    \eta(\textbf{x}) = \tilde{\textbf{w}}^{C(\textbf{x})}\textbf{x} + \tilde{b}^{C(\textbf{x})}, \tag{4}
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(\tilde{\textbf{w}}^{C(\textbf{x})}\)</span> and <span class="math notranslate nohighlight">\(\tilde{b}^{C(\textbf{x})}\)</span> are the coefficients and intercept of the linear model, which can be obtained by some matrix operations of hidden layers weights and biases, considering the corresponding hidden neuron on/off states. The LLM extraction algorithm has been implemented in the Python package <a class="reference external" href="https://github.com/SelfExplainML/Aletheia">Aletheia</a>, and most of its functionalities have been directly integrated into the PiML package.</p>
</section>
<section id="model-training">
<h2><span class="section-number">5.9.3. </span>Model Training<a class="headerlink" href="#model-training" title="Permalink to this heading">¶</a></h2>
<p>In this section, we demonstrate how to train a ReLU-DNN model using PiML. Assuming the data is already prepared, then the ReLU-DNN model can be imported and fitted using PiML’s built-in workflow, as shown below.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">piml.models</span> <span class="kn">import</span> <span class="n">ReluDNNClassifier</span>
<span class="n">exp</span><span class="o">.</span><span class="n">model_train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">ReluDNNClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">40</span><span class="p">),</span> <span class="n">l1_reg</span><span class="o">=</span><span class="mf">0.0002</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;ReLUDNN&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>Below we briefly introduce some of the most important hyperparameters in the ReLU-DNN model.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">hidden_layer_sizes</span></code>: a tuple used to specify the hidden layer structure, by default (40, 40), which means a ReLU-DNN with two hidden layers, each with 40 nodes. The hidden layer size is important for the model’s performance and interpretability. A small-sized ReLU-DNN may be of limited expressive power, and hence, poor model performance. However, if the network size is too large, the model can be extremely complicated and therefore hard to interpret. In practice, it is recommended to start with a relatively larger network size and then apply the L1 penalty to reduce its complexity.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">l1_reg</span></code>: the regularization strength that penalizes the weights, by default 1e-5. In each gradient descent iteration, it shrinks the network weights toward zero, while the bias terms keep unpenalized. Applying the L1 penalty to the network weights may avoid overfitting and enhance model interpretability. In practice, by increasing <code class="docutils literal notranslate"><span class="pre">l1_reg</span></code>, the resulting model tends to have a smaller number of LLMs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>: a float that controls the step size of gradient descent, by default 0.001. The choice of learning rate is critical for model performance. A small <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> may result in an unnecessarily long training time, whereas a large one may make the training process unstable.</p></li>
</ul>
<p>For the full list of hyperparameters, please see the API of <a class="reference external" href="../../modules/generated/piml.models.ReluDNNRegressor.html">ReluDNNRegressor</a> and <a class="reference external" href="../../modules/generated/piml.models.ReluDNNClassifier.html">ReluDNNClassifier</a>.</p>
</section>
<section id="global-interpretation">
<h2><span class="section-number">5.9.4. </span>Global Interpretation<a class="headerlink" href="#global-interpretation" title="Permalink to this heading">¶</a></h2>
<p>Assume a ReLU-DNN model is fitted. Then, it can be inherently interpreted.</p>
<section id="llm-summary-table">
<h3><span class="section-number">5.9.4.1. </span>LLM Summary Table<a class="headerlink" href="#llm-summary-table" title="Permalink to this heading">¶</a></h3>
<p>In <code class="docutils literal notranslate"><span class="pre">exp.model_interpret</span></code>, we can set the parameter <code class="docutils literal notranslate"><span class="pre">show</span></code> to “llm_summary” to get the summary statistics for each LLM.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_interpret</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;ReLUDNN&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;llm_summary&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>In the summary table above, each row represents an LLM with the following statistics.</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">count</span></code>: The number of training samples</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Response</span> <span class="pre">Mean</span></code>: The average of the response values</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Local</span> <span class="pre">AUC</span></code>: The local performance of this LLM in its local region</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Global</span> <span class="pre">AUC</span></code>: The global performance when using this LLM for all training samples</p></li>
</ul>
</div></blockquote>
<p>Such information can help model developers to have a better understanding of the fitted ReLU-DNN model. For example, the first row indicates that the largest LLM has 5153 training samples, with an average response value of 0.105570, a local AUC of 0.584421, and a global AUC of 0.735054. From the results, we find that this LLM’s global performance is even better than its local performance, and a simpler model like GLM may be good enough.</p>
</section>
<section id="parallel-coordinate-plot">
<h3><span class="section-number">5.9.4.2. </span>Parallel Coordinate Plot<a class="headerlink" href="#parallel-coordinate-plot" title="Permalink to this heading">¶</a></h3>
<p>The parallel coordinate plot can be used by setting <code class="docutils literal notranslate"><span class="pre">show</span></code> to “llm_pc”.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_interpret</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;ReLUDNN&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;llm_pc&quot;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/3_models/plot_8_reludnn_cls.html"><img alt="../../_images/sphx_glr_plot_8_reludnn_cls_001.png" src="../../_images/sphx_glr_plot_8_reludnn_cls_001.png" /></a>
</figure>
<p>This plot is used for visualizing coefficients of different LLMs, where each line represents a single LLM. The x-axis shows feature names and the y-axis shows the coefficient values. As this is a static plot, we only plot the top 10 important features, see the <code class="docutils literal notranslate"><span class="pre">Feature</span> <span class="pre">Importance</span> <span class="pre">Plot</span></code> section for details. From the figure above, we can see that <code class="docutils literal notranslate"><span class="pre">Pay_1</span></code> is the most important feature, with a wide range of coefficient values. The second and the third important variables are <code class="docutils literal notranslate"><span class="pre">PAY_AMT1</span></code> and <code class="docutils literal notranslate"><span class="pre">PAY_3</span></code>, respectively.</p>
<p>In general, this plot can be roughly interpreted in the following way.</p>
<ul class="simple">
<li><p>A feature is important when most of its coefficients (absolute values) are large. A feature is shown to have a monotonic increasing effect if all of its coefficients are positive and vice versa.</p></li>
<li><p>When most of the coefficients of a feature are close to zero, it is implied that this feature is trivial and probably can be removed.</p></li>
<li><p>When the range of the coefficients of a feature is large, it is implied that this feature may have a nonlinear effect on the final prediction.</p></li>
</ul>
</section>
<section id="llm-violin-plot">
<h3><span class="section-number">5.9.4.3. </span>LLM Violin Plot<a class="headerlink" href="#llm-violin-plot" title="Permalink to this heading">¶</a></h3>
<p>The violin plot corresponds to the keyword “llm_violin”.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_interpret</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;ReLUDNN&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;llm_violin&quot;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/3_models/plot_8_reludnn_cls.html"><img alt="../../_images/sphx_glr_plot_8_reludnn_cls_002.png" src="../../_images/sphx_glr_plot_8_reludnn_cls_002.png" /></a>
</figure>
<p>Similar to the parallel coordinate plot, this plot shows the LLM coefficient distribution per feature weighted by the sample size of each LLM.</p>
</section>
<section id="feature-importance-plot">
<h3><span class="section-number">5.9.4.4. </span>Feature Importance Plot<a class="headerlink" href="#feature-importance-plot" title="Permalink to this heading">¶</a></h3>
<p>This global feature importance plot (with the keyword “global_fi”) visualizes the most important features in descending order.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_interpret</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;ReLUDNN&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;global_fi&quot;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/3_models/plot_8_reludnn_cls.html"><img alt="../../_images/sphx_glr_plot_8_reludnn_cls_003.png" src="../../_images/sphx_glr_plot_8_reludnn_cls_003.png" /></a>
</figure>
<p>To calculate the feature importance, we first calculate the squared sum of LLM coefficients per feature; then the importance values are normalized such that their sum equals one.</p>
</section>
<section id="llm-profile-plot">
<h3><span class="section-number">5.9.4.5. </span>LLM profile plot<a class="headerlink" href="#llm-profile-plot" title="Permalink to this heading">¶</a></h3>
<p>The local linear profile plot (with the keyword “global_effect_plot”) shows the marginal linear functions upon centering, and it should be used together with the parameter <code class="docutils literal notranslate"><span class="pre">uni_feature</span></code>.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_interpret</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;ReLUDNN&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;global_effect_plot&quot;</span><span class="p">,</span> <span class="n">uni_feature</span><span class="o">=</span><span class="s2">&quot;PAY_1&quot;</span><span class="p">,</span> <span class="n">original_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/3_models/plot_8_reludnn_cls.html"><img alt="../../_images/sphx_glr_plot_8_reludnn_cls_004.png" src="../../_images/sphx_glr_plot_8_reludnn_cls_004.png" /></a>
</figure>
<p>In this plot, each line represents an LLM. The x-axis shows unique values of the specified feature (<code class="docutils literal notranslate"><span class="pre">PAY_1</span></code> in this example), and the y-axis is the marginal effect (coefficient times feature values) of that feature. To make this plot more elegant, we only visualize the top 30 LLMs and the marginal effects are all de-meaned.</p>
</section>
<section id="llm-pairwise-plot">
<h3><span class="section-number">5.9.4.6. </span>LLM pairwise plot<a class="headerlink" href="#llm-pairwise-plot" title="Permalink to this heading">¶</a></h3>
<p>This plot also uses the keyword “global_effect_plot”, and it will be triggered as two features are specified in <code class="docutils literal notranslate"><span class="pre">bi_features</span></code>.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_interpret</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;ReLUDNN&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;global_effect_plot&quot;</span><span class="p">,</span> <span class="n">bi_features</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;PAY_1&quot;</span><span class="p">,</span> <span class="s2">&quot;PAY_3&quot;</span><span class="p">],</span> <span class="n">original_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/3_models/plot_8_reludnn_cls.html"><img alt="../../_images/sphx_glr_plot_8_reludnn_cls_005.png" src="../../_images/sphx_glr_plot_8_reludnn_cls_005.png" /></a>
</figure>
<p>The plot above consists of 2 * 2 subplots, which are used to show how the coefficient would change as the feature value changes.
In particular, each point represents an LLM, and the x-axis is calculated as the average of samples belonging to that LLM. The diagonal subplots show the main effect of the selected two features, and the off-diagonal subplots show the interaction effects.</p>
</section>
</section>
<section id="local-interpretation">
<h2><span class="section-number">5.9.5. </span>Local Interpretation<a class="headerlink" href="#local-interpretation" title="Permalink to this heading">¶</a></h2>
<section id="local-feature-contribution-plot">
<h3><span class="section-number">5.9.5.1. </span>Local Feature Contribution plot<a class="headerlink" href="#local-feature-contribution-plot" title="Permalink to this heading">¶</a></h3>
<p>The local feature importance plot (with the keyword “local_fi”) shows the prediction decomposition of a single training sample.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_interpret</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;ReLUDNN&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;local_fi&quot;</span><span class="p">,</span> <span class="n">sample_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">centered</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">original_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/3_models/plot_8_reludnn_cls.html"><img alt="../../_images/sphx_glr_plot_8_reludnn_cls_006.png" src="../../_images/sphx_glr_plot_8_reludnn_cls_006.png" /></a>
</figure>
<p>The definition of <code class="docutils literal notranslate"><span class="pre">Weight</span></code> and <code class="docutils literal notranslate"><span class="pre">Effect</span></code> can be found in the introduction for GLM. The stems represent the coefficients and the bars show the effect. Similarly, we provide the <code class="docutils literal notranslate"><span class="pre">centered</span></code> option, as shown below.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_interpret</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;ReLUDNN&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;local_fi&quot;</span><span class="p">,</span> <span class="n">sample_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">centered</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">original_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/3_models/plot_8_reludnn_cls.html"><img alt="../../_images/sphx_glr_plot_8_reludnn_cls_007.png" src="../../_images/sphx_glr_plot_8_reludnn_cls_007.png" /></a>
</figure>
<p>After centering, we find that <code class="docutils literal notranslate"><span class="pre">PAY_3</span></code> contributes the most to the final prediction, while <code class="docutils literal notranslate"><span class="pre">PAY_1</span></code> is still the most sensitive feature.</p>
</section>
</section>
<section id="examples">
<h2><span class="section-number">5.9.6. </span>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">¶</a></h2>
<aside class="topic">
<p class="topic-title">Example 1: Friedman</p>
<blockquote>
<div><p>‘Friedman #1’ regression problem, generated via Scikit-Learn.
Inputs X are independent features uniformly distributed on the interval [0, 1]. The output y is created according to the formula:</p>
<div class="math notranslate nohighlight">
\[\begin{align}
   y(x) = 10\ \sin(\pi x_{0} x_{1}) + 20 (x_{2} - 0.5)^{2} + 10 x_{3} + 5 x_{4} + \epsilon.
\end{align}\]</div>
<p>Out of the n_features features, only 5 are used to compute y. The remaining features are independent of y.</p>
</div></blockquote>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/3_models/plot_8_reludnn_reg.html#sphx-glr-auto-examples-3-models-plot-8-reludnn-reg-py"><span class="std std-ref">ReLU DNN Regression (Friedman)</span></a></p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">Examples 2: Taiwan Credit</p>
<blockquote>
<div><p>The second example below demonstrates how to use PiML’s high-code APIs for the TaiwanCredit dataset from the UCI repository. This dataset comprises the credit card details of 30,000 clients in Taiwan from April 2005 to September 2005, and more information can be found on the TaiwanCreditData website. The <code class="docutils literal notranslate"><span class="pre">FlagDefault</span></code> variable serves as the response for this classification problem.</p>
</div></blockquote>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/3_models/plot_8_reludnn_cls.html#sphx-glr-auto-examples-3-models-plot-8-reludnn-cls-py"><span class="std std-ref">ReLU DNN Classification (Taiwan Credit)</span></a></p></li>
</ul>
</aside>
</section>
</section>


        </div>
      <div class="container">
        <footer class="sk-content-footer">
              &copy; Copyright 2022-, PiML-Toolbox authors.
            <a href="../../_sources/guides/models/reludnn.rst.txt" rel="nofollow">Show this page source</a>
        </footer>
      </div>
    </div>
  </div>


  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
      
      const tooltipTriggerList = document.querySelectorAll('[data-bs-toggle="tooltip"]')
      const tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))
  </script>

<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    

<script src="_static/js/vendor/bootstrap.min.js"></script>

</body>
</html>