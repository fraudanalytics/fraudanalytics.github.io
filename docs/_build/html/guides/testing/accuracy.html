<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>

  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>PiML Toolbox</title>
  

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/jupyter-sphinx.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/thebelab.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3" crossorigin="anonymous"></script>
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/thebelab-helper.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>

</head>

<body class="wy-body-for-nav">

  


<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/piml-logo.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../modules/classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Examples</a>
        </li>
     </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
  <div class="d-flex" id="sk-doc-wrapper">
      <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
      <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
      <div id="sk-sidebar-wrapper" class="border-right">
        <div class="sk-sidebar-toc-wrapper">
          <div class="sk-sidebar-toc-logo">
            <a href="../../index.html">
              <img
                class="sk-brand-img"
                src="../../_static/piml-logo.png"
                alt="logo"/>
            </a>
          </div>
          <!--div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
              <a href="../testing.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6. Diagnostic Suite">Prev</a><a href="../testing.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6. Diagnostic Suite">Up</a>
              <a href="weakspot.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6.2. WeakSpot">Next</a>
          </div-->
              <div class="sk-sidebar-toc">
              
                <ul>
                
                
                
                
                
                
                <li>
                  <a href="../../user_guide.html" class="sk-toc-active">User Guide</a>
                </li>
                <ul>
                
                  <li>
                    <a href="../introduction.html" class="">1. Introduction</a>
                    
                  </li>
                
                  <li>
                    <a href="../data.html" class="">2. Data Pipeline</a>
                    
                  </li>
                
                  <li>
                    <a href="../train.html" class="">3. Model Train and Tune</a>
                    
                  </li>
                
                  <li>
                    <a href="../explain.html" class="">4. Post-hoc Explainability</a>
                    
                  </li>
                
                  <li>
                    <a href="../models.html" class="">5. Interpretable Models</a>
                    
                  </li>
                
                  <li>
                    <a href="../testing.html" class="sk-toc-active">6. Diagnostic Suite</a>
                    
                    <ul>
                      
                        <li class="sk-toctree-l3">
                          <a href="">6.1. Accuracy</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="weakspot.html">6.2. WeakSpot</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="overfit.html">6.3. Overfit</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="reliability.html">6.4. Reliability</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="robustness.html">6.5. Robustness</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="resilience.html">6.6. Resilience</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="fairness.html">6.7. Fairness</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="segmented_diagnose.html">6.8. Segmented</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="scored_test.html">6.9. Scored Test</a>
                        </li>
                      
                    </ul>
                    
                  </li>
                
                  <li>
                    <a href="../compare.html" class="">7. Model Comparison</a>
                    
                  </li>
                
                  <li>
                    <a href="../cases.html" class="">8. Case Studies</a>
                    
                  </li>
                
                </ul>
                
                
                
                
                </ul>
              </div>
        </div>
      </div>
      <div id="sk-page-content-wrapper">
        <div class="sk-page-content container-fluid body px-md-3" role="main">
          
  <style type="text/css">
  div.body div.toctree-wrapper ul {
      padding-left: 0;
  }

  div.body li.toctree-l1 {
      padding: 0 0 0.5em 0;
      list-style-type: none;
      font-size: 150%;
      font-weight: bold;
  }

  div.body li.toctree-l2 {
      font-size: 70%;
      list-style-type: square;
      font-weight: normal;
      margin-left: 40px;
  }

  div.body li.toctree-l3 {
      font-size: 85%;
      list-style-type: circle;
      font-weight: normal;
      margin-left: 40px;
  }

  div.body li.toctree-l4 {
      margin-left: 40px;
  }

</style><section id="accuracy">
<h1><span class="section-number">6.1. </span>Accuracy<a class="headerlink" href="#accuracy" title="Permalink to this heading">¶</a></h1>
<p>This section introduces how to utilize the <code class="docutils literal notranslate"><span class="pre">model_diagnose</span></code> function to evaluate model performance for regression and binary classification tasks. It’s important to note that all the metrics discussed here are based on the APIs provided by <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html">sklearn</a>.</p>
<section id="regression-tasks">
<h2><span class="section-number">6.1.1. </span>Regression Tasks<a class="headerlink" href="#regression-tasks" title="Permalink to this heading">¶</a></h2>
<p>For regression tasks, PiML offers the following three metrics to evaluate model performance:</p>
<ul class="simple">
<li><p><strong>Mean Squared Error</strong> (MSE): It measures the average squared difference between the predicted and actual values. It provides a measure of the overall model performance, with lower values indicating better accuracy.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{align}
    MSE = \frac{1}{n}\sum_{i=1}^{n}(y_{i} - \hat{y}_{i})^{2}. \tag{1}
\end{align}\]</div>
<ul class="simple">
<li><p><strong>Mean Absolute Error</strong> (MAE): It calculates the average absolute difference between the predicted and actual values. It provides a measure of the average magnitude of errors, regardless of their direction.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{align}
    MAE = \frac{1}{n}\sum_{i=1}^{n}|y_{i} - \hat{y}_{i}|. \tag{2}
\end{align}\]</div>
<ul class="simple">
<li><p><strong>R-squared</strong> (R2): This is a statistical measure that represents the proportion of the variance in the target variable that can be explained by the features in the model. Note that the value of R2 is always between 0 and 1 for the training set, with 1 indicating a perfect fit and 0 indicating no relationship between the variables. However, it is possible to have negative values for the testing set.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{align}
    R2 = 1-\frac{\sum_{i=1}^{n}(y_{i} - \hat{y}_{i})^{2} } {\sum_{i=1}^{n}(y_{i} - \bar{y})^{2} }. \tag{3}
\end{align}\]</div>
<section id="accuracy-table">
<h3><span class="section-number">6.1.1.1. </span>Accuracy Table<a class="headerlink" href="#accuracy-table" title="Permalink to this heading">¶</a></h3>
<p>By setting <code class="docutils literal notranslate"><span class="pre">show</span></code> to “accuracy_table”, the function would generate a summary table for various metrics. The provided code below demonstrates the process of generating an accuracy table for a fitted XGB2 model using the BikeSharing dataset.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s1">&#39;accuracy_table&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MSE</th>
      <th>MAE</th>
      <th>R2</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Train</th>
      <td>0.0090</td>
      <td>0.0669</td>
      <td>0.7382</td>
    </tr>
    <tr>
      <th>Test</th>
      <td>0.0095</td>
      <td>0.0688</td>
      <td>0.7287</td>
    </tr>
    <tr>
      <th>Gap</th>
      <td>0.0005</td>
      <td>0.0019</td>
      <td>-0.0095</td>
    </tr>
  </tbody>
</table><p>This table displays performance metrics for both the train and test sets, along with the difference (gap) between these two sets. A desirable model exhibits a small MAE or MSE (approaching zero) and an R2 value close to 1. It is also important to minimize the gap between the train and test sets, as it indicates whether the model is overfitting.</p>
</section>
<section id="residual-plot">
<h3><span class="section-number">6.1.1.2. </span>Residual Plot<a class="headerlink" href="#residual-plot" title="Permalink to this heading">¶</a></h3>
<p>The residual is the disparity between the actual response and the predicted response values. A residual plot is employed to showcase the relationship between residuals and a specific feature. An ideal residual plot, known as the null residual plot, exhibits a random scattering of points forming a band of approximately constant width around the identity line. In PiML, we can generate residual plots for the testing set by configuring the <code class="docutils literal notranslate"><span class="pre">show</span></code> parameter as “residual_plot” and specifying the desired <code class="docutils literal notranslate"><span class="pre">show_feature</span></code>. The <code class="docutils literal notranslate"><span class="pre">use_test</span></code> argument, which is set to False by default (using the training set), can be set to True to generate the residual plot for the testing set.</p>
<p><strong>Numerical Features</strong></p>
<p>The first example below displays the residual plot against a numerical feature <code class="docutils literal notranslate"><span class="pre">hr</span></code>. Upon examining the plot, it becomes evident that there is considerable variability in the residuals across different hours of the day. Notably, the range of residuals observed during rush hours is significantly wider than that of non-peak hours. This observation is logical since the demand for bike sharing is much higher during rush hours compared to non-peak hours, making predictions during rush hours relatively more challenging.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;accuracy_residual&quot;</span><span class="p">,</span> <span class="n">show_feature</span><span class="o">=</span><span class="s2">&quot;hr&quot;</span><span class="p">,</span>
                   <span class="n">use_test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">original_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/4_testing/plot_0_accuracy_reg.html"><img alt="../../_images/sphx_glr_plot_0_accuracy_reg_001.png" src="../../_images/sphx_glr_plot_0_accuracy_reg_001.png" /></a>
</figure>
<p><strong>Categorical Features</strong></p>
<p>The following example presents a bar chart residual plot for a categorical feature <code class="docutils literal notranslate"><span class="pre">season</span></code>. The plot illustrates that the residuals are evenly distributed across various seasons, which is a positive indication.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;accuracy_residual&quot;</span><span class="p">,</span> <span class="n">show_feature</span><span class="o">=</span><span class="s2">&quot;season&quot;</span><span class="p">,</span>
                   <span class="n">use_test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">original_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/4_testing/plot_0_accuracy_reg.html"><img alt="../../_images/sphx_glr_plot_0_accuracy_reg_002.png" src="../../_images/sphx_glr_plot_0_accuracy_reg_002.png" /></a>
</figure>
<p><strong>Target Feature</strong></p>
<p>In addition to generating residual plots for input features, we can also generate residual plots against the target feature (<code class="docutils literal notranslate"><span class="pre">cnt</span></code> in the BikeSharing data). This allows us to assess the disparity in residuals across different values of the target. The resulting plot reveals a noticeable correlation between the residuals and the response, indicating that there may be a need for additional features to improve the model’s performance.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;accuracy_residual&quot;</span><span class="p">,</span> <span class="n">show_feature</span><span class="o">=</span><span class="s2">&quot;cnt&quot;</span><span class="p">,</span>
                   <span class="n">use_test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/4_testing/plot_0_accuracy_reg.html"><img alt="../../_images/sphx_glr_plot_0_accuracy_reg_003.png" src="../../_images/sphx_glr_plot_0_accuracy_reg_003.png" /></a>
</figure>
<p><strong>Predicted Value</strong></p>
<p>Lastly, the residual plot against the predicted values is depicted below. To generate this plot, the <code class="docutils literal notranslate"><span class="pre">show_feature</span></code> argument should be set to the name of the response feature followed by “_predict”. From this plot, we can observe a positive relationship between the predicted values and the variability of residuals. This observation aligns with the earlier residual plot, indicating that predicting bike sharing during rush hours is more challenging than during non-peak hours. Furthermore, we notice that the scatter plot appears to be constrained at the lower end by the line <span class="math notranslate nohighlight">\(x+y=0\)</span>. This boundary exists because the predicted values (<span class="math notranslate nohighlight">\(x\)</span>) plus the residuals (<span class="math notranslate nohighlight">\(y\)</span>) equal the response variable, and the minimum value for bike sharing is zero.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;accuracy_residual&quot;</span><span class="p">,</span> <span class="n">show_feature</span><span class="o">=</span><span class="s2">&quot;cnt_predict&quot;</span><span class="p">,</span>
                   <span class="n">use_test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/4_testing/plot_0_accuracy_reg.html"><img alt="../../_images/sphx_glr_plot_0_accuracy_reg_004.png" src="../../_images/sphx_glr_plot_0_accuracy_reg_004.png" /></a>
</figure>
</section>
</section>
<section id="binary-classification">
<h2><span class="section-number">6.1.2. </span>Binary Classification<a class="headerlink" href="#binary-classification" title="Permalink to this heading">¶</a></h2>
<p>For binary classification tasks, the following metrics are supported:</p>
<ul class="simple">
<li><p><strong>Accuracy-score (ACC)</strong>: The accuracy score is a commonly employed metric for evaluating classification models. It is calculated by dividing the number of correctly classified samples by the total number of samples. However, when working with imbalanced datasets, relying solely on accuracy may not provide an accurate assessment of model performance. In such cases, it is crucial to consider additional metrics such as AUC and F1-score to obtain a more comprehensive evaluation.</p></li>
<li><p><strong>Area Under the ROC Curve (AUC)</strong>: AUC provides a meaningful measure of how effectively the classifier distinguishes between positive and negative classes. Its values range from 0 to 1, where a model with completely incorrect predictions would have an AUC of 0.0, and a model with perfect predictions would have an AUC of 1.0. A random classifier, on the other hand, would have an AUC of approximately 0.5, indicating that its predictive ability is no better than random guessing.</p></li>
<li><p><strong>F1-score (F1)</strong>: The F1 score is calculated as the harmonic mean of precision and recall. The formula for computing the F1 score is as follows:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{align}
   F1 = 2\frac{Precision \cdot Recall}{Precision+Recall}=\frac{2TP}{2TP+FP+FN}. \tag{4}
\end{align}\]</div>
<p>The F1 score combines both precision and recall into a single metric, providing a balanced measure of a classifier’s performance. By considering both precision (the ability to correctly identify positive instances) and recall (the ability to capture all positive instances), the F1 score offers a comprehensive evaluation of the model’s effectiveness in handling both true positives and false negatives.</p>
<ul class="simple">
<li><p><strong>Log loss (LogLOss)</strong>: is also known as cross-entropy loss, which is a popular evaluation metric for binary classification problems. Log loss increases as the predicted probability diverges from the actual label.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{align}
   LogLoss = - \frac{1}{n}\sum_{i=1}^{n}y_{i}\log(p_{i}) + (1 - y_{i})\log(1 - p_{i}). \tag{5}
\end{align}\]</div>
<ul class="simple">
<li><p><strong>Brier Score (Brier)</strong>: is another metric commonly used to assess the performance of probabilistic predictions, particularly in the context of binary classification problems. It measures the mean squared difference between predicted probabilities and the actual outcomes. The Brier Score is defined as:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{align}
    Brier = \frac{1}{n}\sum_{i=1}^{n}(y_{i} - p_{i})^{2}. \tag{6}
\end{align}\]</div>
<section id="id1">
<h3><span class="section-number">6.1.2.1. </span>Accuracy Table<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h3>
<p>In a binary classification task, the accuracy table consists of three essential metrics: “ACC” (Accuracy), “AUC” (Area Under the ROC Curve), and “F1” (F1 Score). Here’s an example that demonstrates the usage of the accuracy table for a fitted XGB2 model on the TaiwanCredit dataset:</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;accuracy_table&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ACC</th>
      <th>AUC</th>
      <th>LogLoss</th>
      <th>Brier</th>
      <th>F1</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Train</th>
      <td>0.8219</td>
      <td>0.7978</td>
      <td>0.4759</td>
      <td>0.4196</td>
      <td>0.1316</td>
    </tr>
    <tr>
      <th>Test</th>
      <td>0.8290</td>
      <td>0.7728</td>
      <td>0.4797</td>
      <td>0.4252</td>
      <td>0.1319</td>
    </tr>
    <tr>
      <th>Gap</th>
      <td>0.0071</td>
      <td>-0.0251</td>
      <td>0.0038</td>
      <td>0.0057</td>
      <td>0.0004</td>
    </tr>
  </tbody>
</table>
</div>
</div><p>The accuracy table for binary classification tasks follows a similar structure to that of regression tasks. By considering the values of “ACC,” “AUC,”, “F1,”, “LogLoss”, and “Brier”, as well as the “Gap” column, the accuracy table provides a comprehensive evaluation of the model’s performance in binary classification tasks.</p>
</section>
<section id="id2">
<h3><span class="section-number">6.1.2.2. </span>Residual Plot<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h3>
<p>This plot displays the prediction residuals (between the target and the predicted probability) against a specific variable of interest. To generate this plot, we utilize the “residual_plot” option for the <code class="docutils literal notranslate"><span class="pre">show</span></code> parameter and specify the feature name of interest using the <code class="docutils literal notranslate"><span class="pre">show_feature</span></code> parameter. This plot shares similarities with the residual plots used in regression tasks, providing insights into the relationship between the residuals and the variable of interest. By examining this plot, we can analyze patterns and trends in the residuals and assess how they vary with changes in the selected feature.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;residual_plot&quot;</span><span class="p">,</span> <span class="n">show_feature</span><span class="o">=</span><span class="s2">&quot;PAY_1&quot;</span><span class="p">,</span>
                   <span class="n">use_test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">original_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/4_testing/plot_0_accuracy_cls.html"><img alt="../../_images/sphx_glr_plot_0_accuracy_cls_002.png" src="../../_images/sphx_glr_plot_0_accuracy_cls_002.png" /></a>
</figure>
<p>This plot illustrates the absolute difference between the predicted probability and the actual response (0 or 1). Since the response variable is binary, we plot the absolute residuals separately for class 0 and class 1. Additionally, we include smoothing curves for each class, which are estimated using the locally weighted scatterplot smoothing (<a class="reference external" href="https://en.wikipedia.org/wiki/Local_regression">Lowess</a>) estimator.</p>
<p>It is important to note that the feature of interest in this plot can be either the input feature, the response variable, or the predicted probability. By examining this plot, we can gain insights into the magnitude and patterns of the absolute residuals for each class, allowing us to evaluate the model’s performance and identify any potential discrepancies between the predicted probabilities and the actual responses.</p>
</section>
<section id="accuracy-plot">
<h3><span class="section-number">6.1.2.3. </span>Accuracy Plot<a class="headerlink" href="#accuracy-plot" title="Permalink to this heading">¶</a></h3>
<p>To comprehensively evaluate the performance of a binary classification model, an additional plot can be generated by setting the <code class="docutils literal notranslate"><span class="pre">show</span></code> parameter to “accuracy_plot”. This plot comprises three subplots that depict the confusion matrix, ROC curve, and precision-recall curve for the testing set.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;accuracy_plot&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/4_testing/plot_0_accuracy_cls.html"><img alt="../../_images/sphx_glr_plot_0_accuracy_cls_001.png" src="../../_images/sphx_glr_plot_0_accuracy_cls_001.png" /></a>
</figure>
<ul class="simple">
<li><p><strong>Confusion matrix</strong>: The left plot shows the confusion matrix, a valuable tool for evaluating classification model performance. The diagonal elements represent the number of instances where the predicted label matches the true label, indicating correct predictions. These values correspond to the true positives (TP) and true negatives (TN) of the model. On the other hand, the off-diagonal elements represent the mislabeled instances, including false positives (FP) and false negatives (FN). A higher value on the diagonal indicates better performance and more accurate predictions.</p></li>
<li><p><strong>ROC curve</strong>: In the middle, the ROC curve illustrates the relationship between the true positive rate (TPR) and the false positive rate (FPR) at various threshold settings for classifying instances. The ROC curve can help determine the optimal threshold setting for the classifier by identifying the point on the curve that maximizes the TPR while minimizing the FPR. The closer the ROC curve is to the top-left corner of the plot, the better the classifier’s performance in terms of achieving higher sensitivity while maintaining a lower false positive rate.</p></li>
<li><p><strong>Precision-recall curve</strong>: The right one displays the precision-recall curve, a useful measure for evaluating models when classes are imbalanced. High recall but low precision means that the model is correctly identifying a large number of positive instances (true positives), but it also includes many irrelevant instances. In contrast, low recall but high precision means that the model is correctly identifying a smaller proportion of positive instances (true positives), but the instances it identifies as positive are more likely to be true positives. This plot helps determine the optimal threshold for classifying instances and assessing the tradeoff between precision and recall.</p></li>
</ul>
</section>
</section>
<section id="examples">
<h2><span class="section-number">6.1.3. </span>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">¶</a></h2>
<aside class="topic">
<p class="topic-title">Example 1: BikeSharing</p>
<blockquote>
<div><p>The first example below demonstrates how to use PiML with its high-code APIs for developing machine learning models for the BikeSharing data from the UCI repository, which consists of 17,389 samples of hourly counts of rental bikes in Capital bikeshare system; see details. The response <code class="docutils literal notranslate"><span class="pre">cnt</span></code> (hourly bike rental counts) is continuous and it is a regression problem.</p>
</div></blockquote>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/4_testing/plot_0_accuracy_reg.html#sphx-glr-auto-examples-4-testing-plot-0-accuracy-reg-py"><span class="std std-ref">Accuracy: Regression</span></a></p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">Examples 2: Taiwan Credit</p>
<blockquote>
<div><p>The second example below demonstrates how to use PiML’s high-code APIs for the TaiwanCredit dataset from the UCI repository. This dataset comprises the credit card details of 30,000 clients in Taiwan from April 2005 to September 2005, and more information can be found on the TaiwanCreditData website. The data can be loaded directly into PiML, although it requires some preprocessing. The FlagDefault variable serves as the response for this classification problem.</p>
</div></blockquote>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/4_testing/plot_0_accuracy_cls.html#sphx-glr-auto-examples-4-testing-plot-0-accuracy-cls-py"><span class="std std-ref">Accuracy: Classification</span></a></p></li>
</ul>
</aside>
</section>
</section>


        </div>
      <div class="container">
        <footer class="sk-content-footer">
              &copy; Copyright 2022-, PiML-Toolbox authors.
            <a href="../../_sources/guides/testing/accuracy.rst.txt" rel="nofollow">Show this page source</a>
        </footer>
      </div>
    </div>
  </div>


  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
      
      const tooltipTriggerList = document.querySelectorAll('[data-bs-toggle="tooltip"]')
      const tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))
  </script>

<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    

<script src="_static/js/vendor/bootstrap.min.js"></script>

</body>
</html>