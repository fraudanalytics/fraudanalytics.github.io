<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>

  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>PiML Toolbox</title>
  

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/jupyter-sphinx.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/thebelab.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3" crossorigin="anonymous"></script>
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/thebelab-helper.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>

</head>

<body class="wy-body-for-nav">

  


<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/piml-logo.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Examples</a>
        </li>
     </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
  <div class="d-flex" id="sk-doc-wrapper">
      <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
      <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
      <div id="sk-sidebar-wrapper" class="border-right">
        <div class="sk-sidebar-toc-wrapper">
          <div class="sk-sidebar-toc-logo">
            <a href="../../index.html">
              <img
                class="sk-brand-img"
                src="../../_static/piml-logo.png"
                alt="logo"/>
            </a>
          </div>
          <!--div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
              <a href="piml.models.ExplainableBoostingClassifier.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="piml.models.ExplainableBoostingClassifier">Prev</a><a href="../classes.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="API Reference">Up</a>
              <a href="piml.models.GAMINetClassifier.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="piml.models.GAMINetClassifier">Next</a>
          </div-->
              <div class="sk-sidebar-toc">
                <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">piml.models</span></code>.GAMINetRegressor</a><ul>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor</span></code></a><ul>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.certify_mono"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.certify_mono</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.fine_tune_selected"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.fine_tune_selected</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.fit"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.fit</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.get_clarity_loss"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.get_clarity_loss</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.get_interaction_raw_output"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.get_interaction_raw_output</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.get_main_effect_raw_output"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.get_main_effect_raw_output</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.get_metadata_routing"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.get_metadata_routing</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.get_mono_loss"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.get_mono_loss</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.get_params"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.get_params</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.get_raw_output"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.get_raw_output</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.load"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.load</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.parse_model"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.parse_model</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.partial_dependence"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.partial_dependence</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.partial_derivatives"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.partial_derivatives</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.predict"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.predict</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.save"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.save</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.score"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.score</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.set_params"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.set_params</span></code></a></li>
<li><a class="reference internal" href="#piml.models.GAMINetRegressor.set_score_request"><code class="docutils literal notranslate"><span class="pre">GAMINetRegressor.set_score_request</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#examples-using-piml-models-gaminetregressor">Examples using <code class="docutils literal notranslate"><span class="pre">piml.models.GAMINetRegressor</span></code></a></li>
</ul>
</li>
</ul>

              </div>
        </div>
      </div>
      <div id="sk-page-content-wrapper">
        <div class="sk-page-content container-fluid body px-md-3" role="main">
          
  <section id="piml-models-gaminetregressor">
<h1><code class="xref py py-mod docutils literal notranslate"><span class="pre">piml.models</span></code>.GAMINetRegressor<a class="headerlink" href="#piml-models-gaminetregressor" title="Permalink to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">piml.models.</span></span><span class="sig-name descname"><span class="pre">GAMINetRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_types</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interact_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subnet_size_main_effect</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(20,)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subnet_size_interaction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(20,</span> <span class="pre">20)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ReLU'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1000,</span> <span class="pre">1000,</span> <span class="pre">1000)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.001,</span> <span class="pre">0.001,</span> <span class="pre">0.0001)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stop_thres</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">('auto',</span> <span class="pre">'auto',</span> <span class="pre">'auto')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size_inference</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter_per_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gam_sample_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_sample_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">heredity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_clarity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_mono</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mono_increasing_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mono_decreasing_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mono_sample_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_interaction_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boundary_clip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Generalized additive model with pairwise interaction regressor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feature_names</strong><span class="classifier">list or None, default=None</span></dt><dd><p>The list of feature names.</p>
</dd>
<dt><strong>feature_types</strong><span class="classifier">list or None, default=None</span></dt><dd><p>The list of feature types. Available types include “numerical” and “categorical”.</p>
</dd>
<dt><strong>interact_num</strong><span class="classifier">int, default=10</span></dt><dd><p>The max number of interactions to be included in the second stage training.</p>
</dd>
<dt><strong>subnet_size_main_effect</strong><span class="classifier">tuple of int, default=(20, )</span></dt><dd><p>The hidden layer architecture of each subnetwork in the
main effect block.</p>
</dd>
<dt><strong>subnet_size_interaction</strong><span class="classifier">tuple of int, default=(20, 20)</span></dt><dd><p>The hidden layer architecture of each subnetwork in the
interaction block.</p>
</dd>
<dt><strong>activation_func</strong><span class="classifier">{“ReLU”, “Sigmoid”, “Tanh”}, default=”ReLU”</span></dt><dd><p>The name of the activation function.</p>
</dd>
<dt><strong>max_epochs</strong><span class="classifier">tuple of int, default=(1000, 1000, 1000)</span></dt><dd><p>The max number of epochs in the first (main effect training),
second (interaction training), and third (fine tuning) stages,
respectively.</p>
</dd>
<dt><strong>learning_rates</strong><span class="classifier">tuple of float, default=(1e-3, 1e-3, 1e-4)</span></dt><dd><p>The initial learning rates of Adam optimizer in the first
(main effect training), second (interaction training), and
third (fine tuning) stages, respectively.</p>
</dd>
<dt><strong>early_stop_thres</strong><span class="classifier">tuple of int or “auto”, default=[“auto”, “auto”, “auto”]</span></dt><dd><p>The early stopping threshold in the first (main effect training),
second (interaction training), and third (fine tuning) stages,
respectively.
In auto mode, the value is set to max(5, min(5000 * n_features
/ (max_iter_per_epoch * batch_size), 100)).</p>
</dd>
<dt><strong>batch_size</strong><span class="classifier">int, default=1000</span></dt><dd><p>The batch size.
Note that it should not be larger than the training size * (1 - validation ratio).</p>
</dd>
<dt><strong>batch_size_inference</strong><span class="classifier">int, default=10000</span></dt><dd><p>The batch size used in the inference stage.
It is imposed to avoid out-of-memory issue when dealing very large dataset.</p>
</dd>
<dt><strong>max_iter_per_epoch</strong><span class="classifier">int, default=100</span></dt><dd><p>The max number of iterations per epoch.
In the init stage of model fit, its value will be clipped
by min(max_iter_per_epoch, int(sample_size / batch_size)).
For each epoch, the data would be reshuffled and only the
first “max_iter_per_epoch” batches would be used for training.
It is imposed to make the training scalable for very large dataset.</p>
</dd>
<dt><strong>val_ratio</strong><span class="classifier">float, default=0.2</span></dt><dd><p>The validation ratio, should be greater than 0 and smaller
than 1.</p>
</dd>
<dt><strong>warm_start</strong><span class="classifier">bool, default=True</span></dt><dd><p>Initialize the network by fitting a rough B-spline based
GAM model with tensor product interactions.
The initialization is performed by,
1) fit B-spline GAM as teacher model,
2) generate random samples from the teacher model,
3) fit each subnetwork using the generated samples.
And it is used for both main effect and interaction subnetwork initialization.</p>
</dd>
<dt><strong>gam_sample_size</strong><span class="classifier">int, default=5000</span></dt><dd><p>The sub-sample size for GAM fitting as warm_start=True.</p>
</dd>
<dt><strong>mlp_sample_size</strong><span class="classifier">int, default=1000</span></dt><dd><p>The generated sample size for individual subnetwork fitting
as warm_start=True.</p>
</dd>
<dt><strong>heredity</strong><span class="classifier">bool, default=True</span></dt><dd><p>Whether to perform interaction screening subject to heredity
constraint.</p>
</dd>
<dt><strong>loss_threshold</strong><span class="classifier">float, default=0.01</span></dt><dd><p>The loss tolerance threshold for selecting fewer main effects or
interactions, according to the validation performance.
For instance, assume the best validation performance is achieved
when using 10 main effects; if only use the top 5 main effects
also gives similar validation performance, we could prune the
last 5 by setting this parameter to be positive.</p>
</dd>
<dt><strong>reg_clarity</strong><span class="classifier">float, default=0.1</span></dt><dd><p>The regularization strength of marginal clarity constraint.</p>
</dd>
<dt><strong>reg_mono</strong><span class="classifier">float, default=0.1</span></dt><dd><p>The regularization strength of monotonicity constraint.</p>
</dd>
<dt><strong>mono_sample_size</strong><span class="classifier">int, default=1000</span></dt><dd><p>As monotonicity constraint is used, we would generate some data points
uniformly within the feature space per epoch, to impose the monotonicity
regularization in addition to original training samples.</p>
</dd>
<dt><strong>mono_increasing_list</strong><span class="classifier">tuple of str, default=()</span></dt><dd><p>The feature name tuple subject to monotonic increasing constraint.</p>
</dd>
<dt><strong>mono_decreasing_list</strong><span class="classifier">tuple of str, default=()</span></dt><dd><p>The feature name tuple subject to monotonic decreasing constraint.</p>
</dd>
<dt><strong>include_interaction_list</strong><span class="classifier">tuple of (str, str), default=()</span></dt><dd><p>The tuple of interaction to be included for fitting,
each interaction is expressed by (feature_name1, feature_name2).</p>
</dd>
<dt><strong>boundary_clip</strong><span class="classifier">bool, default=True</span></dt><dd><p>In the inference stage, whether to clip the feature values by their
min and max values in the training data.</p>
</dd>
<dt><strong>normalize</strong><span class="classifier">bool, default=True</span></dt><dd><p>Whether to normalize the data before inputting to the network.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">bool, default=False</span></dt><dd><p>Whether to output the training logs.</p>
</dd>
<dt><strong>n_jobs</strong><span class="classifier">int, default=10</span></dt><dd><p>The number of cpu cores for parallel computing. -1 means all the
available cpus will be used.</p>
</dd>
<dt><strong>device</strong><span class="classifier">string, default=”cpu”</span></dt><dd><p>The hardware device name used for training.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">int, default=0</span></dt><dd><p>The random seed.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>net_</strong><span class="classifier">torch network object</span></dt><dd><p>The fitted GAMI-Net module.</p>
</dd>
<dt><strong>data_dict_density_</strong><span class="classifier">dict</span></dt><dd><p>The dict containing the marginal density of each input feature.</p>
</dd>
<dt><strong>err_train_main_effect_training_</strong><span class="classifier">list of float</span></dt><dd><p>The training loss history in the main effect fitting stage.</p>
</dd>
<dt><strong>err_val_main_effect_training_</strong><span class="classifier">list of float</span></dt><dd><p>The validation loss history in the main effect fitting stage.</p>
</dd>
<dt><strong>err_train_interaction_training_</strong><span class="classifier">list of float</span></dt><dd><p>The training loss history in the interaction fitting stage.</p>
</dd>
<dt><strong>err_val_interaction_training_</strong><span class="classifier">list of float</span></dt><dd><p>The validation loss history in the interaction fitting stage.</p>
</dd>
<dt><strong>err_train_tuning_</strong><span class="classifier">list of float</span></dt><dd><p>The training loss history in the fine-tuning stage.</p>
</dd>
<dt><strong>err_val_tuning_</strong><span class="classifier">list of float</span></dt><dd><p>The validation loss history in the fine-tuning stage.</p>
</dd>
<dt><strong>interaction_list_</strong><span class="classifier">list of tuples</span></dt><dd><p>The list of feature index pairs (tuple) for each fitted interaction.</p>
</dd>
<dt><strong>active_main_effect_index_</strong><span class="classifier">list of int</span></dt><dd><p>The selected main effect index.</p>
</dd>
<dt><strong>active_interaction_index_</strong><span class="classifier">list of int</span></dt><dd><p>The selected interaction index.</p>
</dd>
<dt><strong>main_effect_val_loss_</strong><span class="classifier">list of float</span></dt><dd><p>The validation loss as the most important main effects are sequentially added.</p>
</dd>
<dt><strong>interaction_val_loss_</strong><span class="classifier">list of float</span></dt><dd><p>The validation loss as the most important interactions are sequentially added.</p>
</dd>
<dt><strong>time_cost_</strong><span class="classifier">list of tuple</span></dt><dd><p>The time cost of each stage.</p>
</dd>
<dt><strong>n_features_in_</strong><span class="classifier">int</span></dt><dd><p>The number of input features.</p>
</dd>
<dt><strong>clarity_</strong><span class="classifier">bool</span></dt><dd><p>Indicator of whether marginal clarity regularization is turned on.</p>
</dd>
<dt><strong>monotonicity_</strong><span class="classifier">bool</span></dt><dd><p>Indicator of whether monotonicity regularization is turned on.</p>
</dd>
<dt><strong>is_fitted_</strong><span class="classifier">bool</span></dt><dd><p>Indicator of whether the model is fitted.</p>
</dd>
<dt><strong>n_interactions_</strong><span class="classifier">int</span></dt><dd><p>The actual number of interactions used in the fitting stage.
It is greater or equal to the number of active interactions.</p>
</dd>
<dt><strong>dummy_values_</strong><span class="classifier">dict</span></dt><dd><p>The dict containing the categories of each categorical feature.</p>
</dd>
<dt><strong>cfeature_num_</strong><span class="classifier">int</span></dt><dd><p>The number of categorical features.</p>
</dd>
<dt><strong>nfeature_num_</strong><span class="classifier">int</span></dt><dd><p>The number of continuous features.</p>
</dd>
<dt><strong>cfeature_names_</strong><span class="classifier">list of str</span></dt><dd><p>The name list of categorical features.</p>
</dd>
<dt><strong>nfeature_names_</strong><span class="classifier">list of str</span></dt><dd><p>The name list of continuous features.</p>
</dd>
<dt><strong>cfeature_index_list_</strong><span class="classifier">list of int</span></dt><dd><p>The index list of categorical features.</p>
</dd>
<dt><strong>nfeature_index_list_</strong><span class="classifier">list of int</span></dt><dd><p>The index list of continuous features.</p>
</dd>
<dt><strong>num_classes_list_</strong><span class="classifier">list of int</span></dt><dd><p>The number of categories for each categorical feature.</p>
</dd>
<dt><strong>mu_list_</strong><span class="classifier">list of float</span></dt><dd><p>The average values of each feature calculated by training data.
For categorical features, the average value is fixed as 0.</p>
</dd>
<dt><strong>std_list_</strong><span class="classifier">list of float</span></dt><dd><p>The standard deviations of each feature calculated by training data.
For categorical features, the average value is fixed as 1.</p>
</dd>
<dt><strong>feature_names_</strong><span class="classifier">list of str</span></dt><dd><p>The feature name list of all input features.</p>
</dd>
<dt><strong>feature_types_</strong><span class="classifier">list of str</span></dt><dd><p>The feature type list of all input features.</p>
</dd>
<dt><strong>min_value_</strong><span class="classifier">torch.tensor</span></dt><dd><p>Containing the min values of input features (obtained from training data).</p>
</dd>
<dt><strong>max_value_</strong><span class="classifier">torch.tensor</span></dt><dd><p>Containing the max values of input features (obtained from training data).</p>
</dd>
<dt><strong>mono_increasing_list_index_</strong><span class="classifier">list of str</span></dt><dd><p>Monotonic increasing features’ name list.</p>
</dd>
<dt><strong>mono_decreasing_list_index_</strong><span class="classifier">list of str</span></dt><dd><p>Monotonic decreasing features’ name list.</p>
</dd>
<dt><strong>include_interaction_list_index_</strong><span class="classifier">list of str</span></dt><dd><p>The list of manually included interactions’ index tuples.</p>
</dd>
<dt><strong>training_generator_</strong><span class="classifier">FastTensorDataLoader</span></dt><dd><p>A loader for training set (the one excluding validation set).</p>
</dd>
<dt><strong>validation_generator_</strong><span class="classifier">FastTensorDataLoader</span></dt><dd><p>A loader for validation set.</p>
</dd>
<dt><strong>warm_init_main_effect_data_</strong><span class="classifier">dict</span></dt><dd><p>The dict containing the information for main effect warm initialization.</p>
</dd>
<dt><strong>warm_init_interaction_data_</strong><span class="classifier">dict</span></dt><dd><p>The dict containing the information for interaction warm initialization.</p>
</dd>
<dt><strong>main_effect_norm_</strong><span class="classifier">np.ndarray</span></dt><dd><p>The variance of each main effect output (calculated by training data).</p>
</dd>
<dt><strong>interaction_norm_</strong><span class="classifier">np.ndarray</span></dt><dd><p>The variance of each main effect output (calculated by training data).</p>
</dd>
<dt><strong>data_dict_global_: dict</strong></dt><dd><p>The global interpretation results, which is generated using the
self.global_explain() function.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.certify_mono" title="piml.models.GAMINetRegressor.certify_mono"><code class="xref py py-obj docutils literal notranslate"><span class="pre">certify_mono</span></code></a>([n_samples])</p></td>
<td><p>Certify whether monotonicity constraint is satisfied.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.fine_tune_selected" title="piml.models.GAMINetRegressor.fine_tune_selected"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fine_tune_selected</span></code></a>(main_effect_list, ...[, ...])</p></td>
<td><p>Fine-tuning with some selected effects (unselected would be pruned).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.fit" title="piml.models.GAMINetRegressor.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(x, y[, sample_weight])</p></td>
<td><p>Fit GAMINetRegressor model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.get_clarity_loss" title="piml.models.GAMINetRegressor.get_clarity_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_clarity_loss</span></code></a>(x[, sample_weight])</p></td>
<td><p>Returns clarity loss of given samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.get_interaction_raw_output" title="piml.models.GAMINetRegressor.get_interaction_raw_output"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_interaction_raw_output</span></code></a>(x)</p></td>
<td><p>Returns numpy array of interactions' raw prediction.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.get_main_effect_raw_output" title="piml.models.GAMINetRegressor.get_main_effect_raw_output"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_main_effect_raw_output</span></code></a>(x)</p></td>
<td><p>Returns numpy array of main effects' raw prediction.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.get_metadata_routing" title="piml.models.GAMINetRegressor.get_metadata_routing"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_metadata_routing</span></code></a>()</p></td>
<td><p>Get metadata routing of this object.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.get_mono_loss" title="piml.models.GAMINetRegressor.get_mono_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_mono_loss</span></code></a>(x[, sample_weight])</p></td>
<td><p>Returns monotonicity loss of given samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.get_params" title="piml.models.GAMINetRegressor.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.get_raw_output" title="piml.models.GAMINetRegressor.get_raw_output"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_raw_output</span></code></a>(x[, main_effect, interaction])</p></td>
<td><p>Returns numpy array of raw prediction.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.load" title="piml.models.GAMINetRegressor.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>([folder, name])</p></td>
<td><p>Load a model from local disk.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.parse_model" title="piml.models.GAMINetRegressor.parse_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parse_model</span></code></a>()</p></td>
<td><p>Interpret the model using functional ANOVA.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.partial_dependence" title="piml.models.GAMINetRegressor.partial_dependence"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_dependence</span></code></a>(fidx, X)</p></td>
<td><p>Partial dependence of given effect index.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.partial_derivatives" title="piml.models.GAMINetRegressor.partial_derivatives"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_derivatives</span></code></a>(feature_name[, n_samples])</p></td>
<td><p>Plot the first-order partial derivatives w.r.t.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.predict" title="piml.models.GAMINetRegressor.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(X[, main_effect, interaction])</p></td>
<td><p>Returns numpy array of predicted values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.save" title="piml.models.GAMINetRegressor.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>([folder, name])</p></td>
<td><p>Save a model to local disk.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.score" title="piml.models.GAMINetRegressor.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a>(X, y[, sample_weight])</p></td>
<td><p>Return the coefficient of determination of the prediction.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.set_params" title="piml.models.GAMINetRegressor.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#piml.models.GAMINetRegressor.set_score_request" title="piml.models.GAMINetRegressor.set_score_request"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_score_request</span></code></a>(*[, sample_weight])</p></td>
<td><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">score</span></code> method.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.certify_mono">
<span class="sig-name descname"><span class="pre">certify_mono</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.certify_mono" title="Permalink to this definition">¶</a></dt>
<dd><p>Certify whether monotonicity constraint is satisfied.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>n_samples</strong><span class="classifier">int, default=10000</span></dt><dd><p>Size of random samples for certifying
the monotonicity constraint.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>mono_status</strong><span class="classifier">bool</span></dt><dd><p>True means monotonicity constraint is satisfied.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.fine_tune_selected">
<span class="sig-name descname"><span class="pre">fine_tune_selected</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">main_effect_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interaction_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stop_thres</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.fine_tune_selected" title="Permalink to this definition">¶</a></dt>
<dd><p>Fine-tuning with some selected effects (unselected would be pruned).</p>
<p>All the network parameters are updated together.
Clarity regularization would be triggered and only penalize
interaction subnetworks.
Monotonic regularization would be imposed if self.mono_decreasing_list
or self.mono_increasing_list are not empty.
After training, the mean and norm of each effect would be updated,
and the subnetworks are also centered.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit GAMINetRegressor model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">np.ndarray of shape (n_samples, n_features)</span></dt><dd><p>Data features.</p>
</dd>
<dt><strong>y</strong><span class="classifier">np.ndarray of shape (n_samples, )</span></dt><dd><p>Target response.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">np.ndarray of shape (n_samples, )</span></dt><dd><p>Sample weight.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>Fitted Estimator.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.get_clarity_loss">
<span class="sig-name descname"><span class="pre">get_clarity_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.get_clarity_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns clarity loss of given samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">np.ndarray of shape (n_samples, n_features)</span></dt><dd><p>Data features</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">np.ndarray of shape (n_samples, )</span></dt><dd><p>Sample weight.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>clarity_loss</strong><span class="classifier">float</span></dt><dd><p>clarity loss.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.get_interaction_raw_output">
<span class="sig-name descname"><span class="pre">get_interaction_raw_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.get_interaction_raw_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns numpy array of interactions’ raw prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">np.ndarray of shape (n_samples, n_features)</span></dt><dd><p>Data features.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>pred</strong><span class="classifier">np.ndarray of shape (n_samples, n_interactions)</span></dt><dd><p>numpy array of interactions’ raw prediction.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.get_main_effect_raw_output">
<span class="sig-name descname"><span class="pre">get_main_effect_raw_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.get_main_effect_raw_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns numpy array of main effects’ raw prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">np.ndarray of shape (n_samples, n_features)</span></dt><dd><p>Data features.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>pred</strong><span class="classifier">np.ndarray of shape (n_samples, n_features)</span></dt><dd><p>numpy array of main effects’ raw prediction.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.get_metadata_routing">
<span class="sig-name descname"><span class="pre">get_metadata_routing</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.get_metadata_routing" title="Permalink to this definition">¶</a></dt>
<dd><p>Get metadata routing of this object.</p>
<p>Please check <span class="xref std std-ref">User Guide</span> on how the routing
mechanism works.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>routing</strong><span class="classifier">MetadataRequest</span></dt><dd><p>A <code class="xref py py-class docutils literal notranslate"><span class="pre">MetadataRequest</span></code> encapsulating
routing information.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.get_mono_loss">
<span class="sig-name descname"><span class="pre">get_mono_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.get_mono_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns monotonicity loss of given samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">np.ndarray of shape (n_samples, n_features)</span></dt><dd><p>Data features.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">np.ndarray of shape (n_samples, ), default=None</span></dt><dd><p>Sample weight.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>mono_loss</strong><span class="classifier">float</span></dt><dd><p>monotonicity loss.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.get_raw_output">
<span class="sig-name descname"><span class="pre">get_raw_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_effect</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interaction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.get_raw_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns numpy array of raw prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">np.ndarray of shape (n_samples, n_features)</span></dt><dd><p>Data features.</p>
</dd>
<dt><strong>main_effect</strong><span class="classifier">bool, default=True</span></dt><dd><p>Whether to include main effects.</p>
</dd>
<dt><strong>interaction</strong><span class="classifier">bool, default=True</span></dt><dd><p>Whether to include interactions.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>pred</strong><span class="classifier">np.ndarray of shape (n_samples, 1)</span></dt><dd><p>numpy array of raw prediction.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">folder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'demo'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a model from local disk.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>folder</strong><span class="classifier">str, default=”./”</span></dt><dd><p>The path of folder.</p>
</dd>
<dt><strong>name</strong><span class="classifier">str, default=”demo”</span></dt><dd><p>Name of the file.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.parse_model">
<span class="sig-name descname"><span class="pre">parse_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.parse_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Interpret the model using functional ANOVA.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>An instance of FANOVAInterpreter</dt><dd><p>The interpretation results.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.partial_dependence">
<span class="sig-name descname"><span class="pre">partial_dependence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fidx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.partial_dependence" title="Permalink to this definition">¶</a></dt>
<dd><p>Partial dependence of given effect index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>fidx</strong><span class="classifier">tuple of int</span></dt><dd><p>The main effect or pairwise interaction feature index.</p>
</dd>
<dt><strong>X</strong><span class="classifier">np.ndarray of shape (n_samples, n_features)</span></dt><dd><p>Data features.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>pred</strong><span class="classifier">np.ndarray of shape (n_samples, )</span></dt><dd><p>numpy array of predicted class values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.partial_derivatives">
<span class="sig-name descname"><span class="pre">partial_derivatives</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.partial_derivatives" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the first-order partial derivatives w.r.t. given feature index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feature_name</strong><span class="classifier">str</span></dt><dd><p>Feature name.</p>
</dd>
<dt><strong>n_samples</strong><span class="classifier">int, default=10000</span></dt><dd><p>Size of random samples to plot the derivatives.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_effect</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interaction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns numpy array of predicted values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">np.ndarray of shape (n_samples, n_features)</span></dt><dd><p>Data features.</p>
</dd>
<dt><strong>main_effect</strong><span class="classifier">bool, default=True</span></dt><dd><p>Whether to include main effects.</p>
</dd>
<dt><strong>interaction</strong><span class="classifier">bool, default=True</span></dt><dd><p>Whether to include interactions.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>pred: np.ndarray of shape (n_samples, )</dt><dd><p>numpy array of predicted values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">folder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'demo'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a model to local disk.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>folder</strong><span class="classifier">str, default=”./”</span></dt><dd><p>The path of folder.</p>
</dd>
<dt><strong>name</strong><span class="classifier">str, default=”demo”</span></dt><dd><p>Name of the file.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the coefficient of determination of the prediction.</p>
<p>The coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> is defined as
<span class="math notranslate nohighlight">\((1 - \frac{u}{v})\)</span>, where <span class="math notranslate nohighlight">\(u\)</span> is the residual
sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)**</span> <span class="pre">2).sum()</span></code> and <span class="math notranslate nohighlight">\(v\)</span>
is the total sum of squares <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>.
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always predicts
the expected value of <code class="docutils literal notranslate"><span class="pre">y</span></code>, disregarding the input features, would get
a <span class="math notranslate nohighlight">\(R^2\)</span> score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>Test samples. For some estimators this may be a precomputed
kernel matrix or a list of generic objects instead with shape
<code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, where <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code>
is the number of samples used in the fitting for the estimator.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_outputs)</span></dt><dd><p>True values for <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span></dt><dd><p>Sample weights.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float</span></dt><dd><p><span class="math notranslate nohighlight">\(R^2\)</span> of <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> w.r.t. <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The <span class="math notranslate nohighlight">\(R^2\)</span> score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with default value of <code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code>.
This influences the <code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput
regressors (except for
<code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#piml.models.GAMINetRegressor.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>). The latter have
parameters of the form <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s
possible to update each component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="piml.models.GAMINetRegressor.set_score_request">
<span class="sig-name descname"><span class="pre">set_score_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.12)"><span class="pre">Union</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#piml.models.GAMINetRegressor" title="piml.models.gaminet.api.GAMINetRegressor"><span class="pre">GAMINetRegressor</span></a></span></span><a class="headerlink" href="#piml.models.GAMINetRegressor.set_score_request" title="Permalink to this definition">¶</a></dt>
<dd><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">score</span></code> method.</p>
<p>Note that this method is only relevant if
<code class="docutils literal notranslate"><span class="pre">enable_metadata_routing=True</span></code> (see <code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.set_config</span></code>).
Please see <span class="xref std std-ref">User Guide</span> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span></code>: metadata is requested, and passed to <code class="docutils literal notranslate"><span class="pre">score</span></code> if provided. The request is ignored if metadata is not provided.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span></code>: metadata is not requested and the meta-estimator will not pass it to <code class="docutils literal notranslate"><span class="pre">score</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str</span></code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p></li>
</ul>
<p>The default (<code class="docutils literal notranslate"><span class="pre">sklearn.utils.metadata_routing.UNCHANGED</span></code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>. Otherwise it has no effect.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample_weight</strong><span class="classifier">str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED</span></dt><dd><p>Metadata routing for <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">score</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>The updated object.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-piml-models-gaminetregressor">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">piml.models.GAMINetRegressor</span></code><a class="headerlink" href="#examples-using-piml-models-gaminetregressor" title="Permalink to this heading">¶</a></h2>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="GAMI-Net Regression (Bike Sharing)"><img alt="" src="../../_images/sphx_glr_plot_7_gaminet_reg_thumb.png" />
<p><a class="reference internal" href="../../auto_examples/3_models/plot_7_gaminet_reg.html#sphx-glr-auto-examples-3-models-plot-7-gaminet-reg-py"><span class="std std-ref">GAMI-Net Regression (Bike Sharing)</span></a></p>
  <div class="sphx-glr-thumbnail-title">GAMI-Net Regression (Bike Sharing)</div>
</div></div><div class="clearer"></div></section>
</section>


        </div>
      <div class="container">
        <footer class="sk-content-footer">
              &copy; Copyright 2022-, PiML-Toolbox authors.
            <a href="../../_sources/modules/generated/piml.models.GAMINetRegressor.rst.txt" rel="nofollow">Show this page source</a>
        </footer>
      </div>
    </div>
  </div>


  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
      
      const tooltipTriggerList = document.querySelectorAll('[data-bs-toggle="tooltip"]')
      const tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))
  </script>

<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    

<script src="_static/js/vendor/bootstrap.min.js"></script>

</body>
</html>