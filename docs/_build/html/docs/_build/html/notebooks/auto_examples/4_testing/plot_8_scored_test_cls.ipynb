{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Scored Test: Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom piml import Experiment\nfrom piml.models import XGB2Classifier\n\nexp = Experiment()\nexp.data_loader(data='TaiwanCredit', silent=True)\nexp.data_prepare(silent=True)\nexp.model_train(model=XGB2Classifier(), name='XGB2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract the required data inputs from PiML workflow \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_x, train_y, _ = exp.get_data(train=True)\ntest_x, test_y, _ = exp.get_data(test=True)\n\ntask_type = 'classification'\nX = np.concatenate([train_x, test_x], axis=0)\ny = np.concatenate([train_y, test_y], axis=0).ravel()\nprediction = exp.get_model(\"XGB2\").estimator.predict(X)\nprediction_proba = exp.get_model(\"XGB2\").estimator.predict_proba(X)[:, -1]\nfeature_names = exp.get_feature_names()\nfeature_types = exp.get_feature_types()\ntarget_name = exp.get_target_name()\ntrain_idx = np.arange(train_x.shape[0])\ntest_idx = np.arange(train_x.shape[0], train_x.shape[0] + test_x.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare the necessary data information\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_dict = {'x': X,\n             'y': y,\n             'task_type': task_type,\n             'prediction': prediction,\n             'prediction_proba': prediction_proba,\n             'feature_names': feature_names,\n             'feature_types': feature_types,\n             'target_name': target_name,\n             'train_idx': train_idx,\n             'test_idx': test_idx}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the accuracy table \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_accuracy_table\nresult = test_accuracy_table(**data_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the accuracy plot \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_accuracy_plot\nresult = test_accuracy_plot(**data_dict, figsize=(10, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the prediction residuals against one feature of interest \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_accuracy_residual\nresult = test_accuracy_residual(**data_dict, show_feature='PAY_1', figsize=(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run weakspot test to detect weak regions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_weakspot\nresult = test_weakspot(**data_dict, slice_features=['PAY_1'], figsize=(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run overfit test to detect overfit regions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_overfit\nresult = test_overfit(**data_dict, slice_method=\"histogram\", slice_features=['PAY_1'], figsize=(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run reliability test to get reliability diagram\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_reliability_perf\nresult = test_reliability_perf(**data_dict, figsize=(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run reliability test to show relationship between prediction uncertainty and feature of interest \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_reliability_marginal\nresult = test_reliability_marginal(**data_dict, show_feature='PAY_1', figsize=(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run reliability test to show data distance between reliable and unreliable samples. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_reliability_distance\nresult = test_reliability_distance(**data_dict, figsize=(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run reliability test to get the calibrated predicted probability vs. original predicted probability. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_reliability_calibration\nresult = test_reliability_calibration(**data_dict, figsize=(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run resilience test to show how model performance changes under distributional shift.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_resilience_perf\nresult = test_resilience_perf(**data_dict, figsize=(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can calculate the distributional difference between good regions and bad regions, e.g. the weak regions and the rest. Similarly, such plot can also be used for other tests, like reliablity. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_resilience_distance\nresult = test_resilience_distance(**data_dict, figsize=(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The distributional difference histogram plot. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_resilience_shift_histogram\nresult = test_resilience_shift_histogram(**data_dict, show_feature='PAY_1', figsize=(5, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The distributional difference density plot. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from piml.scored_test import test_resilience_shift_density\nresult = test_resilience_shift_density(**data_dict, show_feature='PAY_1', figsize=(5, 4))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}